{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By: Akshay Punwatkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Commponents of Part-of-Speech hidden markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from collections import defaultdict \n",
    "from pprint import pprint\n",
    "import tqdm.notebook as tq\n",
    "# nltk.download('brown')\n",
    "# nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.corpus.brown.tagged_sents(tagset='universal')[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hidden_markov():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.observation_matrix = []\n",
    "        self.transition_matrix = []\n",
    "        self.init_state = []\n",
    "        self.observation_dict = defaultdict(lambda : defaultdict(int)) \n",
    "        self.transition_dict = defaultdict(lambda : defaultdict(int))\n",
    "        self.init_state_dict = defaultdict(int)\n",
    "    \n",
    "    def normalize(self, dictionary, level=1, smooth_k= 0):\n",
    "        \"\"\"\n",
    "        Function to convert frequency into probabilites with an option\n",
    "        of Laplace smoothing and log transformation\n",
    "        Input:\n",
    "        dictionary : dictionary containing key value mapping, where the values for each \n",
    "                     key will be normalised. Can be zero or one level nested dict\n",
    "        level : 1, level at with the values to be normalize exists in the dictionary;\n",
    "                Will be \"1\" for unnested  and \"2\" for one level nested dict\n",
    "        smooth_k : 0, laplace smoothing variable        \n",
    "        \n",
    "        Output:\n",
    "        norm_dict : dictionary with normalized values\n",
    "        \"\"\"\n",
    "        \n",
    "        if level == 1:\n",
    "            tot = sum(dictionary.values())\n",
    "            norm_dict = {key:(value+smooth_k)/(tot+value*smooth_k) for key,value in dictionary.items()}\n",
    "            return norm_dict\n",
    "        \n",
    "        elif level == 2:\n",
    "            norm_dict = defaultdict(lambda : defaultdict(int))\n",
    "            for first_key,second_key in dictionary.items():\n",
    "                tot = sum(second_key.values()) \n",
    "                norm_dict[first_key] = {key:(value+smooth_k)/(tot+value*smooth_k) for key,value in second_key.items()}\n",
    "                \n",
    "            return norm_dict    \n",
    "                \n",
    "            \n",
    "    def generate_matrix(self,x,y,transition=True, show_status=True):\n",
    "        \"\"\"\n",
    "        Function to generate transition and observation matrix for the Hidden Markov Model\n",
    "        Input: \n",
    "        x: No of rows in the matrix\n",
    "        y: No of columns in the matrix\n",
    "        transition : True, False if Observation matrix is generated\n",
    "        show_status : True, Flag to show status of process\n",
    "        \n",
    "        Output:\n",
    "        Generated matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        local_dict = self.transition_dict if transition else self.observation_dict\n",
    "\n",
    "        #generating matrix with zero values \n",
    "        gen_matrix = np.zeros([x,y]) \n",
    "        \n",
    "        if transition and show_status:\n",
    "            print(\"Generating Transition matrix\")\n",
    "        elif show_status:\n",
    "            print(\"Generating Observation/Emission matrix\")\n",
    "        \n",
    "        for first_key, second_key in tq.tqdm(local_dict.items(), disable= not show_status):\n",
    "            #x-coordinate corresponding first component\n",
    "            idx_x = self.distinct_pos.index(first_key) if transition else self.distinct_tokens.index(first_key)\n",
    "\n",
    "            for key, value in second_key.items():\n",
    "                #y-coordinate corresponding the the following component of the first component\n",
    "                idx_y = self.distinct_pos.index(key)\n",
    "                gen_matrix[idx_x][idx_y] = format(value, '.5f')\n",
    "            \n",
    "        return gen_matrix    \n",
    "            \n",
    "            \n",
    "    def generate_components(self, corpus,  k=0, show_status=True):\n",
    "        \"\"\"\n",
    "        Function to generate components of Hidden Markow model\n",
    "        Input:\n",
    "        corpus : Corpus (list) of sentences containing (word,part-of-speech) mapping\n",
    "        k : 0, Laplace smoothing coefficient\n",
    "        show_status : True, Flag to show status of process\n",
    "        \n",
    "        Output:\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.distinct_tokens = set()\n",
    "        self.distinct_pos = set()\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        for sentence in self.corpus:   \n",
    "            \n",
    "            #initial state distribution\n",
    "            self.init_state_dict[sentence[0][1]] += 1\n",
    "            \n",
    "            for i in range(len(sentence)):\n",
    "                \n",
    "                curr_word = sentence[i][0].lower()\n",
    "                curr_pos = sentence[i][1]\n",
    "                \n",
    "                #observation dictionary for word : pos : frequency of occurance\n",
    "                self.observation_dict[curr_word][curr_pos] +=1\n",
    "                \n",
    "                if i < len(sentence)-1:\n",
    "                    next_pos = sentence[i+1][1]\n",
    "                    #transition dictionary for pos : next-post : frequency of occurance\n",
    "                    self.transition_dict[curr_pos][next_pos] +=1\n",
    "                \n",
    "                self.distinct_tokens.add(curr_word)\n",
    "        \n",
    "\n",
    "        self.distinct_pos = sorted(self.transition_dict.keys())\n",
    "        m = len(self.distinct_pos)\n",
    "        self.distinct_tokens = sorted(self.distinct_tokens)\n",
    "        n = len(self.distinct_tokens)\n",
    "        \n",
    "        self.transition_dict = self.normalize(self.transition_dict, level=2, smooth_k= k)\n",
    "        self.transition_matrix = self.generate_matrix(m,m,show_status=show_status)\n",
    "    \n",
    "        self.observation_dict = self.normalize(self.observation_dict, level=2, smooth_k = k)\n",
    "        self.observation_matrix = self.generate_matrix(n,m,transition=False,show_status=show_status)\n",
    "        \n",
    "        self.init_state_dict = self.normalize(self.init_state_dict, smooth_k=k)\n",
    "        self.init_state = [self.init_state_dict[k] for k in self.distinct_pos]\n",
    "        \n",
    "        if show_status:\n",
    "            return \"Success !! Components generations completed\"\n",
    "        else:\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Transition matrix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7a8d2b928747f990d318a6cf3d6412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Observation/Emission matrix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b539c6225224b969fe17cc5449c0248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21248.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success !! Components generations completed'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = hidden_markov()\n",
    "hmm.generate_components(corpus,k=1,show_status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06112676056338028,\n",
       " 0.04058721934369603,\n",
       " 0.10778977424823771,\n",
       " 0.0720185614849188,\n",
       " 0.05213764337851929,\n",
       " 0.19382407482060793,\n",
       " 0.16431257835353114,\n",
       " 0.017104099085815394,\n",
       " 0.10194000359259925,\n",
       " 0.029882604055496264,\n",
       " 0.039481268011527376,\n",
       " 0.0005997001499250374]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2413e-01, 5.0240e-02, 1.0028e-01, 5.9370e-02, 8.5850e-02,\n",
       "        1.0731e-01, 1.5187e-01, 2.0950e-02, 6.0100e-02, 1.9810e-02,\n",
       "        1.1570e-01, 2.0100e-03],\n",
       "       [8.2140e-02, 5.5990e-02, 7.3900e-02, 7.6200e-03, 3.2270e-02,\n",
       "        6.0600e-03, 4.0297e-01, 1.2700e-02, 2.4300e-03, 1.8250e-02,\n",
       "        1.5310e-02, 6.7000e-04],\n",
       "       [1.1290e-02, 7.8020e-02, 1.8610e-02, 1.3480e-02, 1.3200e-03,\n",
       "        3.0710e-01, 2.2320e-01, 3.7600e-02, 4.7360e-02, 1.2080e-02,\n",
       "        3.7120e-02, 4.0000e-04],\n",
       "       [1.2284e-01, 1.3084e-01, 1.2161e-01, 8.7980e-02, 1.3590e-02,\n",
       "        7.4740e-02, 3.8720e-02, 1.5340e-02, 3.5090e-02, 2.8630e-02,\n",
       "        2.0591e-01, 3.2000e-04],\n",
       "       [2.2600e-02, 1.0533e-01, 6.3540e-02, 8.1100e-02, 6.0000e-04,\n",
       "        1.3594e-01, 2.2481e-01, 1.9270e-02, 5.0100e-02, 2.3180e-02,\n",
       "        1.3830e-01, 4.5000e-04],\n",
       "       [1.2770e-02, 2.0027e-01, 8.9600e-03, 1.8550e-02, 5.5000e-04,\n",
       "        6.4300e-03, 3.8107e-01, 1.3230e-02, 8.3500e-03, 1.6000e-03,\n",
       "        5.7940e-02, 1.5600e-03],\n",
       "       [2.0927e-01, 1.5440e-02, 1.8613e-01, 2.2320e-02, 4.9910e-02,\n",
       "        1.3920e-02, 1.7507e-01, 9.6200e-03, 1.7440e-02, 1.7180e-02,\n",
       "        1.2591e-01, 4.9000e-04],\n",
       "       [2.0280e-01, 6.4280e-02, 1.2324e-01, 3.1190e-02, 3.2810e-02,\n",
       "        1.0520e-02, 2.7672e-01, 2.3030e-02, 5.4300e-03, 6.8500e-03,\n",
       "        4.2390e-02, 5.7000e-04],\n",
       "       [7.5730e-02, 9.1600e-03, 4.7360e-02, 5.6060e-02, 1.1710e-02,\n",
       "        1.3960e-02, 9.0200e-03, 8.7000e-04, 9.3100e-03, 2.2050e-02,\n",
       "        4.2314e-01, 0.0000e+00],\n",
       "       [4.4700e-02, 1.8790e-02, 8.1930e-02, 2.9880e-02, 8.0300e-03,\n",
       "        7.8250e-02, 3.9990e-02, 7.2500e-03, 3.3500e-03, 8.8100e-03,\n",
       "        3.9831e-01, 3.9000e-04],\n",
       "       [6.6840e-02, 5.5180e-02, 1.4204e-01, 8.7390e-02, 1.1880e-02,\n",
       "        1.5029e-01, 1.0008e-01, 1.2450e-02, 3.7560e-02, 5.9680e-02,\n",
       "        1.6223e-01, 2.2000e-04],\n",
       "       [2.1184e-01, 7.8400e-03, 6.9850e-02, 1.5560e-02, 2.3170e-02,\n",
       "        7.8400e-03, 9.9640e-02, 7.8400e-03, 0.0000e+00, 7.8400e-03,\n",
       "        5.2430e-02, 3.1806e-01]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50417, 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n",
       "       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n",
       "       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n",
       "       ...,\n",
       "       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n",
       "       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n",
       "       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.observation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.distinct_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.     , 0.     , 0.01288, 0.     , 0.5    , 0.     ,\n",
       "       0.     , 0.     , 0.     , 0.     , 0.     ])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hmm.observation_matrix[hmm.distinct_tokens.index('any')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.     , 0.50007, 0.     , 0.     , 0.     , 0.     ,\n",
       "       0.     , 0.     , 0.     , 0.     , 0.     ])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.observation_matrix[hmm.distinct_tokens.index('of')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.observation_matrix[hmm.distinct_tokens.index('0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.11076,\n",
       "       0.46831, 0.     , 0.     , 0.     , 0.     ])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.observation_matrix[hmm.distinct_tokens.index('one')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.     , 0.     , 0.     , 0.     , 0.50286, 0.     ,\n",
       "       0.     , 0.     , 0.     , 0.     , 0.     ])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.observation_matrix[hmm.distinct_tokens.index('those')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.11429,\n",
       "       0.     , 0.     , 0.     , 0.4918 , 0.     ])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.observation_matrix[hmm.distinct_tokens.index('coming')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028494892"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_matrix[hmm.distinct_pos.index('DET')][hmm.distinct_pos.index('VERB')] * \\\n",
    "hmm.observation_matrix[hmm.distinct_tokens.index('coming')][hmm.distinct_pos.index('VERB')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0435524903"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_matrix[hmm.distinct_pos.index('DET')][hmm.distinct_pos.index('NOUN')] * \\\n",
    "hmm.observation_matrix[hmm.distinct_tokens.index('coming')][hmm.distinct_pos.index('NOUN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Implementation of Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\hspace{250px} v_{t}(j)=\\max _{i=1}^{N} v_{t-1}(i) a_{i j} b_{j}\\left(o_{t}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class viterbie():\n",
    "    def __init__(self):\n",
    "        None\n",
    "        \n",
    "    def handle_missing_token(self,token):\n",
    "        return None\n",
    "        \n",
    "    def viterbie(self, obs,pi,A,B,state_list,token_list):\n",
    "        self.states = []\n",
    "        \"\"\"\n",
    "        Function to implement viterbie algorithm for part-of-speech tagging\n",
    "        \n",
    "        obs - the observations [list of ints]\n",
    "        pi  - the initial state probabilities [list of floats]\n",
    "        A   - the state transition probability matrix [2D numpy array]\n",
    "        B   - the observation probability matrix [2D numpy array]\n",
    "        state_list - ordered list of names of the states\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        n = len(obs)\n",
    "        num_states = len(pi)\n",
    "        self.state_prob_matrix = np.zeros([n,num_states])\n",
    "        self.text = []\n",
    "        self.real_state = []\n",
    "        \n",
    "        #iterating over EACH word in the sentence \n",
    "        for i in range(n):\n",
    "            #for the first word, transition probability will be used as prior\n",
    "            #else the probability of last word against each state (POS) will be used as prior\n",
    "            if i == 0:\n",
    "                prior_prob = pi\n",
    "            else:\n",
    "                prior_prob = self.state_prob_matrix[i-1]\n",
    "                \n",
    "            token = obs[i][0].lower()    \n",
    "            self.real_state.append(obs[i][1])\n",
    "            self.text.append(obs[i][0])\n",
    "            \n",
    "            # Observation probability of the given word being in different states (POS). \n",
    "            # If the word doesn't exists in the observation matrix,\n",
    "            # equal probabilites will be assigned against each state for that word.\n",
    "            obs_probab = B[token_list.index(token)] if token in token_list else np.full(num_states,fill_value=1/num_states) \n",
    "            \n",
    "            #iterating over all possible states (POS) for a word\n",
    "            for j in range(num_states):\n",
    "                # for the first word, total probability is the product of the observation probability of the \n",
    "                # word coming a particular state (POS) and initial_state probability of that particular state (POS)\n",
    "                if i == 0:\n",
    "                    self.state_prob_matrix[i][j] = prior_prob[j]*obs_probab[j]\n",
    "                else:\n",
    "                    temp_states = []\n",
    "                    # interating over all possible previous states for a given state (denoted by j)\n",
    "                    for k in range(num_states):\n",
    "                        # for rest of the words, total probability is the product of the observation probability of the \n",
    "                        # word coming a particular state (POS), transition state probability of coming a particular previous (k) \n",
    "                        # state to the current state (j), and prior state probability of previous word in that particular state (k)\n",
    "                        # maximum probability of all the states (k's) is assigned as the current state probability for the word\n",
    "                        state_change_probab = A[k][j]\n",
    "                        temp_states.append(state_change_probab*obs_probab[j]*prior_prob[k])\n",
    "                    self.state_prob_matrix[i][j] = max(temp_states)  \n",
    "                  \n",
    "        self.state_index = np.argmax(self.state_prob_matrix,axis=1)\n",
    "        self.states = [state_list[i] for i in self.state_index]\n",
    "    \n",
    "        return self.states\n",
    "    \n",
    "    def mismatch(self):\n",
    "        \"\"\"\n",
    "        Function to calculate number of mismatch in part-of-speech\n",
    "        between the actual and predicted using viterbie\n",
    "        \"\"\"\n",
    "        mismatch = 0\n",
    "        total = len(self.real_state)\n",
    "        position = []\n",
    "        for i in range(total):\n",
    "            if self.real_state[i] != self.states[i]:\n",
    "                mismatch +=1\n",
    "                position.append(i)\n",
    "                \n",
    "        return \"\\nTotal mismatch : %s/%s,\"%(mismatch,total) + \" at positions %s \"%position + \"Accuracy : %s percent\"%round((total-mismatch)*100/total,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing of Corpus data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text : The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
      "Generated : DET, NOUN, NOUN, ADJ, NOUN, VERB, NOUN, DET, NOUN, ADP, NOUN, ADJ, NOUN, NOUN, VERB, ., DET, NOUN, ., ADP, DET, NOUN, VERB, NOUN, .\n",
      "Original  : DET, NOUN, NOUN, ADJ, NOUN, VERB, NOUN, DET, NOUN, ADP, NOUN, ADJ, NOUN, NOUN, VERB, ., DET, NOUN, ., ADP, DET, NOUN, VERB, NOUN, .\n",
      "\n",
      "Total mismatch : 0/25, at positions [] Accuracy : 100.0 percent\n"
     ]
    }
   ],
   "source": [
    "gen=vit.viterbie(corpus[0],hmm.init_state, hmm.transition_matrix, hmm.observation_matrix, hmm.distinct_pos, hmm.distinct_tokens)\n",
    "print(\"\\nText :\",end=\" \")\n",
    "print(*vit.text, sep= \" \")\n",
    "print(\"Generated :\", end=\" \")\n",
    "print(*gen, sep=', ')\n",
    "print(\"Original  :\", end= \" \") \n",
    "print(*vit.real_state, sep= \", \")\n",
    "print(vit.mismatch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Infrence of Sequence of States (Testing on NEW data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = nltk.corpus.brown.tagged_sents(tagset='universal')[10150:10160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Transition matrix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb48e7335c34658b3ac4b911ba2bac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Observation/Emission matrix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ac9aba9bcc4f3599c406b8c4046bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21248.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success !! Components generations completed'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = hidden_markov()\n",
    "hmm.generate_components(corpus,k=1, show_status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text : Those coming from other denominations will welcome the opportunity to become informed .\n",
      "Generated : DET, NOUN, ADP, ADJ, NOUN, VERB, VERB, DET, NOUN, ADP, VERB, VERB, .\n",
      "Original  : DET, VERB, ADP, ADJ, NOUN, VERB, VERB, DET, NOUN, PRT, VERB, VERB, .\n",
      "\n",
      "Total mismatch : 2/13, at positions [1, 9] Accuracy : 84.62 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : The preparatory class is an introductory face-to-face group in which new members become acquainted with one another .\n",
      "Generated : DET, NOUN, NOUN, VERB, DET, NOUN, NOUN, NOUN, ADP, DET, ADJ, NOUN, VERB, VERB, ADP, NOUN, DET, .\n",
      "Original  : DET, ADJ, NOUN, VERB, DET, ADJ, ADJ, NOUN, ADP, DET, ADJ, NOUN, VERB, VERB, ADP, NUM, DET, .\n",
      "\n",
      "Total mismatch : 4/18, at positions [1, 5, 6, 15] Accuracy : 77.78 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : It provides a natural transition into the life of the local church and its organizations .\n",
      "Generated : PRON, VERB, DET, ADJ, NOUN, ADP, DET, NOUN, ADP, DET, ADJ, NOUN, CONJ, DET, NOUN, .\n",
      "Original  : PRON, VERB, DET, ADJ, NOUN, ADP, DET, NOUN, ADP, DET, ADJ, NOUN, CONJ, DET, NOUN, .\n",
      "\n",
      "Total mismatch : 0/16, at positions [] Accuracy : 100.0 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : Reception into the Church Fellowship\n",
      "Generated : NOUN, ADP, DET, NOUN, NOUN\n",
      "Original  : NOUN, ADP, DET, NOUN, NOUN\n",
      "\n",
      "Total mismatch : 0/5, at positions [] Accuracy : 100.0 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : the total process of evangelism reaches the crescendo when the group of new members stands before the congregation to declare publicly their faith and to be received into the fellowship of the Church .\n",
      "Generated : DET, NOUN, NOUN, ADP, DET, VERB, DET, NOUN, ADV, DET, NOUN, ADP, ADJ, NOUN, VERB, ADP, DET, NOUN, ADP, VERB, ADV, DET, NOUN, CONJ, ADP, VERB, VERB, ADP, DET, NOUN, ADP, DET, NOUN, .\n",
      "Original  : DET, NOUN, NOUN, ADP, NOUN, VERB, DET, NOUN, ADV, DET, NOUN, ADP, ADJ, NOUN, VERB, ADP, DET, NOUN, PRT, VERB, ADV, DET, NOUN, CONJ, PRT, VERB, VERB, ADP, DET, NOUN, ADP, DET, NOUN, .\n",
      "\n",
      "Total mismatch : 3/34, at positions [4, 18, 24] Accuracy : 91.18 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : This should be a high moment in their lives , a never-to-be-forgotten experience .\n",
      "Generated : DET, VERB, VERB, DET, ADJ, NOUN, ADP, DET, NOUN, ., DET, NOUN, NOUN, .\n",
      "Original  : DET, VERB, VERB, DET, ADJ, NOUN, ADP, DET, NOUN, ., DET, ADJ, NOUN, .\n",
      "\n",
      "Total mismatch : 1/14, at positions [11] Accuracy : 92.86 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : They should sense the tremendous significance of joining the spiritual succession reaching back to Christ our Lord and forward to an eternal fellowship with the saints of the ages .\n",
      "Generated : PRON, VERB, NOUN, DET, ADJ, NOUN, ADP, VERB, DET, ADJ, NOUN, VERB, ADV, ADP, NOUN, DET, NOUN, CONJ, ADV, ADP, DET, ADJ, NOUN, ADP, DET, NOUN, ADP, DET, NOUN, .\n",
      "Original  : PRON, VERB, VERB, DET, ADJ, NOUN, ADP, VERB, DET, ADJ, NOUN, VERB, ADV, ADP, NOUN, DET, NOUN, CONJ, ADV, ADP, DET, ADJ, NOUN, ADP, DET, NOUN, ADP, DET, NOUN, .\n",
      "\n",
      "Total mismatch : 1/30, at positions [2] Accuracy : 96.67 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : Every detail of the service merits careful attention -- the hymns , the sermon , the ritual , the right hand of fellowship , the introduction to the congregation , the welcome of the congregation .\n",
      "Generated : DET, NOUN, ADP, DET, NOUN, NOUN, ADJ, NOUN, ., DET, NOUN, ., DET, NOUN, ., DET, NOUN, ., DET, NOUN, NOUN, ADP, NOUN, ., DET, NOUN, ADP, DET, NOUN, ., DET, NOUN, ADP, DET, NOUN, .\n",
      "Original  : DET, NOUN, ADP, DET, NOUN, VERB, ADJ, NOUN, ., DET, NOUN, ., DET, NOUN, ., DET, NOUN, ., DET, ADJ, NOUN, ADP, NOUN, ., DET, NOUN, ADP, DET, NOUN, ., DET, NOUN, ADP, DET, NOUN, .\n",
      "\n",
      "Total mismatch : 2/36, at positions [5, 19] Accuracy : 94.44 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : This is a vital part of their spiritual growth and assimilation .\n",
      "Generated : DET, VERB, DET, ADJ, NOUN, ADP, DET, ADJ, NOUN, CONJ, NOUN, .\n",
      "Original  : DET, VERB, DET, ADJ, NOUN, ADP, DET, ADJ, NOUN, CONJ, NOUN, .\n",
      "\n",
      "Total mismatch : 0/12, at positions [] Accuracy : 100.0 percent\n",
      "-------------------------------------\n",
      "\n",
      "Text : It will help to determine the attitude of the new members toward the Church .\n",
      "Generated : PRON, VERB, VERB, ADP, VERB, DET, NOUN, ADP, DET, ADJ, NOUN, ADP, DET, NOUN, .\n",
      "Original  : PRON, VERB, VERB, PRT, VERB, DET, NOUN, ADP, DET, ADJ, NOUN, ADP, DET, NOUN, .\n",
      "\n",
      "Total mismatch : 1/15, at positions [3] Accuracy : 93.33 percent\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_data)):\n",
    "    vit = viterbie()\n",
    "    gen=vit.viterbie(test_data[i],hmm.init_state, hmm.transition_matrix, hmm.observation_matrix, hmm.distinct_pos, hmm.distinct_tokens)\n",
    "    print(\"\\nText :\",end=\" \")\n",
    "    print(*vit.text, sep= \" \")\n",
    "    print(\"Generated :\", end=\" \")\n",
    "    print(*gen, sep=', ')\n",
    "    print(\"Original  :\", end= \" \") \n",
    "    print(*vit.real_state, sep= \", \")\n",
    "    print(vit.mismatch())\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
